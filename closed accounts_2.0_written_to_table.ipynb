{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5175b29e",
   "metadata": {},
   "source": [
    "## Code & Logic for Determining Closed Accounts\n",
    "\n",
    "Consider the following hypothesis:\n",
    "\n",
    "---\n",
    "> $H_1$: It is possible to predict (with some metric) if an account will be closed within the next 30-days using at minimum the following feature set:\n",
    "\n",
    ">> {\n",
    "    prior 30-transactions,\n",
    "    is joint account?,\n",
    "    age of account owner\n",
    "}\n",
    "---\n",
    "### STEP 1: (logical breakdown of hypothesis exploration)\n",
    "> When considering $H_1$ or $H_0$ how do we find accounts which are closed?\n",
    "\n",
    "For the aforementioned hypothesis:\n",
    "This Jupyter Notebook is concerned with determining **closed accounts**, solely, where additional separate files are to follow for subsequent steps.\n",
    "\n",
    "#### IMPORTANT NOTE: Exploration carried out via BELLCO_PROD_DNA.OSIBANK, Bellco Credit Union's institutional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246a0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import col, lit, sum as sum_, max as max_\n",
    "from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "import snowflake.snowpark.functions as f\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5254c",
   "metadata": {},
   "source": [
    "# Functions to Establish & Work With Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2284c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_snowpark_session():\n",
    "    \"\"\"Function to establish a Snowflake-Snowpark session.\n",
    "    Authentication is required and accomplished via web browser -- a new tab will be opened \n",
    "    which can be closed after authentication is completed.\n",
    "    NOTE: 'account' and 'user' must be specified.  \n",
    "    \"\"\"\n",
    "    # open yaml config file containing user, authenticator, etc.\n",
    "    with open('config.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    \n",
    "    return Session.builder.configs(config).create()\n",
    "\n",
    "\n",
    "def get_session_info(session):\n",
    "    \"\"\"Function to printout current Snowflake session information.\"\"\"\n",
    "    \n",
    "    print(f\"\"\"\n",
    "{'account':<15}{session.get_current_account()}\n",
    "{'role':<15}{session.get_current_role()}\n",
    "{'warehouse':<15}{session.get_current_warehouse()}\n",
    "{'database':<15}{session.get_current_database()}\n",
    "{'schema':<15}{session.get_current_schema()}\n",
    "\"\"\")\n",
    "    \n",
    "    \n",
    "def get_view(session, view, ret_rows=1, printSession=True):\n",
    "    \"\"\"Function to examine chosen VIEW including printing the number of rows found, \n",
    "    while also while printing out current session info if desired.\"\"\"\n",
    "    \n",
    "    if printSession:\n",
    "        get_session_info(snow_session)\n",
    "    \n",
    "    print(f\"\\nrecords returned from VIEW={view}: {snow_session.table(view).count():,}\")\n",
    "    \n",
    "    return snow_session.table(view).select(\"*\").limit(ret_rows).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349d4f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "\n",
      "account        \"otscuso\"\n",
      "role           \"OTS_INNOVATION\"\n",
      "warehouse      \"OTS_INNOVATION_WH\"\n",
      "database       \"BELLCO_PROD_DNA\"\n",
      "schema         \"OSIBANK\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_session = create_snowpark_session()\n",
    "\n",
    "# set database & schema to be used for session\n",
    "snow_session.use_database(\"BELLCO_PROD_DNA\")\n",
    "snow_session.use_schema(\"OSIBANK\")\n",
    "\n",
    "get_session_info(snow_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ac4ea",
   "metadata": {},
   "source": [
    "# Important VIEW exploration\n",
    "\n",
    "- **VIEW** - a virtual table which does not retain data, rather it saves a SQL statement/query to be run later, which given the sheer volume of data in this case is a memory savings opportunity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c6986",
   "metadata": {},
   "source": [
    "## `ACCTSTAT`\n",
    "\n",
    "**Naive approach:** find all closed accounts by CLS code, alone, found in this table; this would find all accounts with a registered closure however *not necessarily* a final closure disposition.\n",
    "\n",
    "This VIEW effectively provides a **key for account status types** via columns `ACCTSTATCD` & `ACCTSTATDESC`\n",
    "\n",
    "Closed accounts can be interpreted to mean accounts with the following status, however per direction provided **Closed** was used:\n",
    "- **Closed**\n",
    "- **Closed with Balances Remaining**\n",
    "- **Chargeoff** - meaning an account (possibly a loan) which was a loss to the Financial Institute (FI), likley meaning the account was closed\n",
    "\n",
    "Other important observations\n",
    "- Assumed - interpreted to mean the FI took control of the account, likely indicating the account was forcibly handed over & possibly closed, although not necessarily (consider judge-mandated terms of a bankruptcy, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b810fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "records returned from VIEW=ACCTSTAT: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCTSTATCD</th>\n",
       "      <th>ACCTSTATDESC</th>\n",
       "      <th>DATELASTMAINT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPR</td>\n",
       "      <td>Approved</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLS</td>\n",
       "      <td>Closed</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO</td>\n",
       "      <td>Chargeoff</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CWB</td>\n",
       "      <td>Closed with Balances Remaining</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DORM</td>\n",
       "      <td>Dormant</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IACT</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORIG</td>\n",
       "      <td>Originating</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACT</td>\n",
       "      <td>Active</td>\n",
       "      <td>1994-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NPFM</td>\n",
       "      <td>Non-Accrual</td>\n",
       "      <td>1996-04-22 11:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DENI</td>\n",
       "      <td>Loan Denied</td>\n",
       "      <td>1995-12-28 12:45:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASSM</td>\n",
       "      <td>Assumed</td>\n",
       "      <td>1997-11-19 17:26:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACCTSTATCD                    ACCTSTATDESC       DATELASTMAINT\n",
       "0        APPR                        Approved 1994-01-01 00:00:00\n",
       "1         CLS                          Closed 1994-01-01 00:00:00\n",
       "2          CO                       Chargeoff 1994-01-01 00:00:00\n",
       "3         CWB  Closed with Balances Remaining 1994-01-01 00:00:00\n",
       "4        DORM                         Dormant 1994-01-01 00:00:00\n",
       "5        IACT                        Inactive 1994-01-01 00:00:00\n",
       "6        ORIG                     Originating 1994-01-01 00:00:00\n",
       "7         ACT                          Active 1994-01-01 00:00:00\n",
       "8        NPFM                     Non-Accrual 1996-04-22 11:37:41\n",
       "9        DENI                     Loan Denied 1995-12-28 12:45:40\n",
       "10       ASSM                         Assumed 1997-11-19 17:26:25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    get_view(snow_session, view=\"ACCTSTAT\", ret_rows=11, printSession=False)\n",
    ")[['ACCTSTATCD', 'ACCTSTATDESC', 'DATELASTMAINT']]    # grab important columns, only, from underlying VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393fcab9",
   "metadata": {},
   "source": [
    "## `ACCTACCTSTATHIST`\n",
    "\n",
    "The specific VIEW `ACCTACCTSTATHIST` captures account status via `ACCTSTAT.ACCTSTATCD == 'CLS'`\n",
    "- ACCTNBR - member account number\n",
    "- ACCSTATCD - account status (Active, Closed, etc.) \n",
    "- EFFDATETIME - effective datetime of account status change. **i.e. the provided datetime when an account was closed, etc.**\n",
    "- TIMEUNIQUEEXTN - The Time Unique Extension Number is a system assigned primary key. SYSTEM USE ONLY!\n",
    "\n",
    "BELLCO's Snowflake database has been chosen here for the sake of simplicity, however, so long as the other CU's databases follow the same naming convention and structure they may be accessed similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b38e9",
   "metadata": {},
   "source": [
    "## Determine which column(s) can be used to ID most recent Member Account status\n",
    "Limit rows returned from DF to *more than 2 transactions per account* for especially pronounced exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b1502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "test_obj = get_view(snow_session, view=\"ACCTACCTSTATHIST\", ret_rows=10000, printSession=True)\n",
    "test_df = pd.DataFrame(test_obj)      \n",
    "# test_df.sort_values(['ACCTNBR', 'EFFDATETIME'])\n",
    "\n",
    "test_df[test_df['ACCTNBR'].isin(\n",
    "    test_df.groupby('ACCTNBR').count()[test_df.groupby('ACCTNBR').count()['EFFDATETIME'] > 2].index.values)].sort_values(\n",
    "    ['ACCTNBR', 'EFFDATETIME'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf72f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "test_df[test_df['ACCTNBR'].isin(\n",
    "    test_df.groupby('ACCTNBR').count()[test_df.groupby('ACCTNBR').count()['EFFDATETIME'] > 2].index.values)].sort_values(\n",
    "    ['ACCTNBR', 'DATELASTMAINT'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4192ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "test_df[test_df['ACCTNBR'].isin(\n",
    "    test_df.groupby('ACCTNBR').count()[test_df.groupby('ACCTNBR').count()['EFFDATETIME'] > 2].index.values)].sort_values(\n",
    "    ['ACCTNBR', 'TIMEUNIQUEEXTN'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da213d3b",
   "metadata": {},
   "source": [
    "`TIMEUNIQUEEXTN` values appears unique and the higher the number for a given account appears to represent more recent account activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17153737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "int64\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df['EFFDATETIME'].dtype)\n",
    "print(test_df['TIMEUNIQUEEXTN'].dtype)\n",
    "print(test_df['DATELASTMAINT'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e4d91",
   "metadata": {},
   "source": [
    "#### Test groupby aggregation equivalence for 3 select columns EFFDATETIME, TIMEUNIQUEEXTN, DATELASTMAINT to determine best variable for max aggregation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49fa23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A == B: True\n",
      "A == C: True\n",
      "B == C: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcorley\\AppData\\Local\\Temp\\ipykernel_23512\\101138240.py:1: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "\n",
    "# EFFDATETIME & TIMEUNIQUEEXTN will be the same; however, some variation may occur w/ DATELASTMAINT as it's system update\n",
    "# per direction provided by Cindy Lee on the Database team\n",
    "A = test_df.groupby('ACCTNBR').max('EFFDATETIME')\n",
    "B = test_df.groupby('ACCTNBR').max('TIMEUNIQUEEXTN')\n",
    "C = test_df.groupby('ACCTNBR').max('DATELASTMAINT')\n",
    "\n",
    "def test_equivalence(df1, df2):\n",
    "    try:\n",
    "        assert_frame_equal(df1, df2)\n",
    "        return True\n",
    "    except: \n",
    "        return False\n",
    "    \n",
    "\n",
    "print(\"A == B:\", test_equivalence(A, B))\n",
    "print(\"A == C:\", test_equivalence(A, C))\n",
    "print(\"B == C:\", test_equivalence(B, C))    # if A == B & A == C then B == C by Transitive Property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71552e",
   "metadata": {},
   "source": [
    "##### Outcome:\n",
    "Any of `EFFDATETIME`, `TIMEUNIQUEEXTN`, or `DATELASTMAINT` are suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58fb65",
   "metadata": {},
   "source": [
    "## `ACCT`\n",
    "Contains transactional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d05c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "test_obj = get_view(snow_session, view=\"acct\".upper(), ret_rows=10000, printSession=True)\n",
    "test_df = pd.DataFrame(test_obj)      \n",
    "print(test_df.columns.values)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52fec40",
   "metadata": {},
   "source": [
    "# Pandas DataFrame Implementation/Exploration for Determining Closed Accounts\n",
    "#### Local machine Implementation leveraging Pandas familiarity (not ideal given volume of data)\n",
    "* See Snowflake implementation below for distributed computing version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fcd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "# limit our returned number of rows to 100,000 vs 12.6+ million\n",
    "# consider: filtering prior to limit\n",
    "\n",
    "view_obj = get_view(snow_session, view=\"ACCTACCTSTATHIST\", ret_rows=100000, printSession=True)\n",
    "view_df = pd.DataFrame(view_obj)\n",
    "# print(view_df.columns.to_list())    # print column headers if needed for larger VIEWs\n",
    "view_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d10d8",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE:\n",
    "`EFFDATETIME` is the effective datetime of the status change, meaning when an account was closed the status was switched to 'CLS' (closed) for the given datetime captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d269a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "# Closed accounts: CLS or CWB - closed w/ remaining balance; chargeoffs would also be closed, but allowed to pay\n",
    "clsd_acct = view_df[\n",
    "#     (view_df['ACCTSTATCD'] == \"CLS\") | (view_df['ACCTSTATCD'] == \"Chargeoff\") | (view_df['ACCTSTATCD'] == \"CWB\")\n",
    "    (view_df['ACCTSTATCD'] == \"CLS\")\n",
    "]\n",
    "\n",
    "# clsd_acct.groupby('ACCTNBR').max('EFFDATETIME')) returns a Series which needs to be merged/joined back to full DF\n",
    "clsd_df = pd.DataFrame(clsd_acct.groupby('ACCTNBR').max('TIMEUNIQUEEXTN')).merge(\n",
    "    clsd_acct, \n",
    "    on=\"TIMEUNIQUEEXTN\", \n",
    "    how='inner'\n",
    ")[['ACCTNBR', 'ACCTSTATCD', 'TIMEUNIQUEEXTN', 'EFFDATETIME', 'POSTDATE']]\n",
    "clsd_df[clsd_df['EFFDATETIME'].between(pd.to_datetime('01/01/2022'), pd.to_datetime('08/01/2022'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "909b6087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 20851 entries, 12 to 99999\n",
      "Series name: EFFDATETIME\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "20851 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 325.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLS    20851\n",
       "Name: ACCTSTATCD, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsd_acct['EFFDATETIME'].info()\n",
    "clsd_acct['ACCTSTATCD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c0f15",
   "metadata": {},
   "source": [
    "# Snowflake DataFrame Implementation for Determining Closed Accounts\n",
    "#### Snowflake DataFrame construct\n",
    "https://docs.snowflake.com/en/developer-guide/snowpark/python/working-with-dataframes#label-snowpark-python-dataframe-construct\n",
    "#### Snowflake efficiency\n",
    "https://docs.snowflake.com/en/user-guide/querying-persisted-results\n",
    "\n",
    "\"When a query is executed, the result is persisted (i.e. cached) for a period of time. At the end of the time period, the result is purged from the system.\"\n",
    "\n",
    "### Distributed implementation via Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b859628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.snowflake.com/developer-guide/snowpark/reference/python/api/snowflake.snowpark.DataFrame.groupBy.html\n",
    "\n",
    "def get_closed_accounts_for_timeframe(session, begin, end, lim=200):\n",
    "    \"\"\"\n",
    "    This function represents a Snowflake-Snowpark implementation to find closed accounts for a given look-back period.  \n",
    "    \n",
    "    Accounts w/ the status code 'CLS' (OSIBANK-DNA system code for closed) for the given timeframe are found.\n",
    "    These accounts are then aggregated by account number where the most recent/highest unique 'TIMEUNIQUEEXTN' column value\n",
    "    is determined for an account via the aggregate function 'max'. The most recent [unique] value for the period \n",
    "    is needed as it's possible to encounter accounts which were closed but subsequently re-opened in the given period.\n",
    "    'TIMEUNIQUEEXTN' represents a unique system key generated for account status changes.\n",
    "    After this query is carried out then a join is performed on accounts to pull full rows of data matching 'TIMEUNIQUEEXTN'.\n",
    "    \n",
    "    Parameters:\n",
    "        session (Snowflake session object): used to establish a connection to the desired Snowflake instance.\n",
    "        begin (string: MM/DD/YYYY): a date which specifies the beginning of the lookback period inclusively.\n",
    "        end (string: MM/DD/YYYY): a date which specifies the end of the lookback period inclusively.\n",
    "        lim (int): an integer which specifies a query return result limit, a row return max.\n",
    "        \n",
    "    Returns:\n",
    "        Snowflake DataFrame: A DataFrame containing the closed account information.\n",
    "    \"\"\"    \n",
    "    # session.table() creates a Snowflake DataFrame from a table, view or stream\n",
    "    df_table = session.table(\"ACCTACCTSTATHIST\")\n",
    "    \n",
    "    # get accounts which match ultimate/final account status 'CLS'\n",
    "    latest_status = (df_table\n",
    "                     .filter((col('ACCTSTATCD') == 'CLS'))\n",
    "#                      .filter(col('ACCTSTATCD') == 'CLS') | (col('ACCTSTATCD') == 'Chargeoff') | (col('ACCTSTATCD') == 'CWB')\n",
    "                     .group_by('ACCTNBR')\n",
    "                     .agg(max_(col('TIMEUNIQUEEXTN')).alias('TIMEUNIQUEEXTN'))\n",
    "                    )\n",
    "    \n",
    "    # merge latest_status back to ACCTACCTSTATHIST DataFrame created from VIEW\n",
    "    return (latest_status\n",
    "            .join(\n",
    "                df_table, \n",
    "                on='TIMEUNIQUEEXTN', \n",
    "                how='inner', \n",
    "                lsuffix='_'\n",
    "            )\n",
    "            .select(\n",
    "                col('ACCTNBR'), \n",
    "                col('ACCTSTATCD'), \n",
    "                col('TIMEUNIQUEEXTN'), \n",
    "                col('EFFDATETIME')\n",
    "            )\n",
    "            .filter((f.to_date('EFFDATETIME') >= begin) & (f.to_date('EFFDATETIME') <= end))\n",
    "            .limit(lim)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db039d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "closed_accounts = get_closed_accounts_for_timeframe(snow_session, '1/1/2022', '8/1/2022', lim=None)\n",
    "closed_accounts.show()\n",
    "closed_accounts.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e1325",
   "metadata": {},
   "source": [
    "While several account status codes exist indicating account closure, simply \"Closed\" appears to be the most common code encountered by far (99.99+%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f327ef",
   "metadata": {},
   "source": [
    "## Instantiate/establish new Snowflake session for writing closed accounts to Snowflake table\n",
    "By creating a new Snowflake session I am able to keep the transactional data separate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e741da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "\n",
      "account        \"otscuso\"\n",
      "role           \"OTS_INNOVATION\"\n",
      "warehouse      \"OTS_INNOVATION_WH\"\n",
      "database       \"OTS_INNOVATION_DB\"\n",
      "schema         \"JOEL_C\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate/establish snowflake session\n",
    "snow_session_ots_innov = create_snowpark_session()\n",
    "\n",
    "# set database & schema to be used for session\n",
    "snow_session_ots_innov.use_database(\"OTS_INNOVATION_DB\")\n",
    "snow_session_ots_innov.use_schema(\"JOEL_C\")\n",
    "\n",
    "get_session_info(snow_session_ots_innov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2027f",
   "metadata": {},
   "source": [
    "# Write closed accounts  back to Snowflake\n",
    "The following Snowflake table OTS_INNOVATION_DB.JOEL_C.SAMPLE_ACCOUNTS is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71612888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# THE FOLLOWING OUTPUT IS WITHELD DUE TO SENSITIVE Personally identifiable information (PII)\n",
    "\n",
    "pd_df = closed_accounts.to_pandas()\n",
    "\n",
    "# using a local timezone is needed to change the default datetime conversion, a known snowflake_dataframe.to_pandas() issue\n",
    "# https://github.com/snowflakedb/snowflake-connector-python/issues/319#issuecomment-764145625\n",
    "pd_df['EFFDATETIME'] = pd_df['EFFDATETIME'].dt.tz_localize('UTC')\n",
    "\n",
    "# pd_df = pd_df.to_frame()\n",
    "pd_df['acct_open'] = 0\n",
    "pd_df['effective_date'] = pd_df['EFFDATETIME'].dt.date\n",
    "pd_df['window_start'] = pd.to_datetime('1/1/2022')\n",
    "pd_df['window_end'] = pd.to_datetime('8/1/2022')\n",
    "\n",
    "pd_df[['ACCTNBR', 'acct_open', 'effective_date', 'window_start', 'window_end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d84afa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Snowflake session below references the new DB & Schema.\n",
    "\n",
    "pd_df = closed_accounts.to_pandas()\n",
    "\n",
    "# using a local timezone is needed to change the default datetime conversion, a known snowflake_df.to_pandas() issue\n",
    "# https://github.com/snowflakedb/snowflake-connector-python/issues/319#issuecomment-764145625\n",
    "pd_df['EFFDATETIME'] = pd_df['EFFDATETIME'].dt.tz_localize('UTC')\n",
    "\n",
    "# pd_df = pd_df.to_frame()\n",
    "pd_df['acct_open'] = 0\n",
    "pd_df['effective_date'] = pd_df['EFFDATETIME'].dt.date\n",
    "pd_df['window_start'] = pd.to_datetime('1/1/2022')\n",
    "pd_df['window_end'] = pd.to_datetime('8/1/2022')\n",
    "\n",
    "# code below overcomes known datetime issue when writing a Pandas DataFrame to a Snowpark DataFrame\n",
    "pd_df['window_start'] = pd_df['window_start'].dt.tz_localize('UTC').dt.date\n",
    "pd_df['window_end'] = pd_df['window_end'].dt.tz_localize('UTC').dt.date\n",
    "\n",
    "\n",
    "# cls_acct_schema = StructType(\n",
    "#     [\n",
    "#         StructField( 'ACCTNBR', IntegerType() ), \n",
    "#         StructField( 'ACCTSTATCD', StringType() ), \n",
    "#         StructField( 'TIMEUNIQUEEXTN', IntegerType() ), \n",
    "#         StructField( 'EFFDATETIME', TimestampType() ) \n",
    "#     ]\n",
    "# )\n",
    "\n",
    "(snow_session_ots_innov    \n",
    "#  .create_dataframe(pd_df, schema=cls_acct_schema)\n",
    " .create_dataframe(pd_df[['ACCTNBR', 'acct_open', 'effective_date', 'window_start', 'window_end']])\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .save_as_table(\"SAMPLE_ACCOUNTS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12ed03",
   "metadata": {},
   "source": [
    "### Check write results\n",
    "* We get results and create a Pandas DataFrame from them for the ease of viewing, as DataFrame output is displayed nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a360dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcorley\\AppData\\Local\\Temp\\ipykernel_18020\\1884991516.py:7: FutureWarning: this method is deprecated in favour of `Styler.hide(axis='index')`\n",
      "  output_df.style.hide_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5bd9c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5bd9c_level0_col0\" class=\"col_heading level0 col0\" >ACCT_OPEN</th>\n",
       "      <th id=\"T_5bd9c_level0_col1\" class=\"col_heading level0 col1\" >COUNT(ACCT_OPEN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5bd9c_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_5bd9c_row0_col1\" class=\"data row0 col1\" >58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5bd9c_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_5bd9c_row1_col1\" class=\"data row1 col1\" >58000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d6d5a45b50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(snow_session_ots_innov.sql(\"\"\"\n",
    "SELECT acct_open, COUNT(acct_open)\n",
    "FROM OTS_INNOVATION_DB.JOEL_C.SAMPLE_ACCOUNTS \n",
    "GROUP BY acct_open;\n",
    "\"\"\").collect())\n",
    "\n",
    "output_df.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dc7040",
   "metadata": {},
   "source": [
    "# Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1452d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07767636",
   "metadata": {},
   "source": [
    "# LESSONS LEARNED\n",
    "* Snowflake is nearly identical syntactically to Apache Spark/PySpark which is covered in DU's CS4334 Parallel & Distributed Computing course through the use of DataBricks which uses/builds on Apache Spark\n",
    "    - follows functional progamming paradigm\n",
    "    - Snowflake follows Python in using underscores '_' intead of camel case which Apache Spark uses for function calls (Scala/Java origin)\n",
    "    - A parallel computing DataFrame implementaion is available w/in Snowflake's Snowpark library\n",
    "* The naive implementation for determining closed accounts given the underlying database construction involves filtering for accounts which only have the \"CLS\" status code\n",
    "    - There is much nuance to accounts found w/in the financial system transactional databases, for example accounts which have been closed during a lookback period can be subsequently reopened at any time and therefore we need the ultimate account disposition, only.  Much forethought and familiarity with the underlying database construction is required to properly query.\n",
    "* In order to determine closed accounts for a lookback period an aggregation was needed using .group_by() on the account number followed by finding the maximum unique transaction number to determine the final disposition of an account during said period.\n",
    "* Given the volume of transactional data a parallel implementation is really the only viable approach while working with millions of rows of data, as opposed to using Pandas DataFrames on a local machine.\n",
    "    - after Snowpark DataFrame filtering we can convert the Snowpark DataFrame to a Pandas DataFrame for use\n",
    "* When a Snowflake SQL query is executed the result is persisted (i.e. cached) for a period of time **automatically**, unlike Apache Spark/DataBricks which requires function calls to achieve this end such as .persist()\n",
    "* The sheer volume of database tables involved with a financial transactional system (a CU or a bank, etc.) is extraordinary and will require a data dictionary to effectively utilize, or otherwise subject matter expertise (SME).  Unfortunately, OTS' database department informed me a formal data dictionary was unavailble and therefore I relied primarily on my own observations\n",
    "* Snowflake offers contract terms with pay per query, so unecessary queries should be avoided where possible (think millions of rows of data), although I had encountered no issues with this as I purposefully chose to limit returned results while examining database views.\n",
    "* Snowflake has a built-in function for writing Snowflake DataFrames to a database table w/in your Snowflake instance.  We do not need to use SQLAlchemy or a similar SQL library (SQLite, etc.) for Python.\n",
    "* Snowflake database tables (or SQL tables for that matter) can have comments attached to columns which can then be read out simultaneously via SQL query\n",
    "* In a production environment the best practice is to use a config file which holds sensitive login/authorization credentials separate from the main file(s).  There are several Python libraries available for reading in these files including 1 for YAML files which has been used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65035a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775acd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
